{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import urllib.request"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup\n",
    "\n",
    "The Player class will make the data easier to sort through and separate unique objects, since we'll be collecting photos from rosters over several seasons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Player:\n",
    "    def __init__(self, name, team, jpg):\n",
    "        self.name=name;\n",
    "        self.team=team;\n",
    "        self.jpg=jpg;\n",
    "    def __eq__(self, other):\n",
    "        return self.name==other.name\n",
    "    def __hash__(self):\n",
    "        return hash(('name', self.name, 'team', self.team, 'jpg', self.jpg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following functions are for scraping the NHL website. \n",
    "(An exception for the 2004-2005 season, which was cancelled due to the lockout, is handled accordingly. #history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_multiseasons(base_url, seasonrange_floor, seasonrange_ceiling):\n",
    "    allplayers=[];\n",
    "    for year in range(seasonrange_floor, seasonrange_ceiling):\n",
    "        try:\n",
    "            url=base_url+\"/\"+str(year);\n",
    "            team=base_url.split('/')[3];\n",
    "            allplayers=allplayers+getPlayers(url, team);\n",
    "            print(\"Team: \",team,\", Season: \", year,\"added \\n\")\n",
    "        except:\n",
    "            print(\"2004-2005 season unavailable.\")\n",
    "    return allplayers;\n",
    "        \n",
    "def getPlayers(url, team):\n",
    "    \n",
    "    player_list=[];\n",
    "    html=urllib.request.urlopen(url)\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    \n",
    "    images = soup.find_all(\"img\",\"player-photo\")\n",
    "    lastnames=soup.find_all(\"span\",\"name-col__item name-col__lastName\")\n",
    "    firstnames=soup.find_all(\"span\",\"name-col__item name-col__firstName\")\n",
    "    \n",
    "    player_zip=zip(firstnames, lastnames, images)\n",
    "    for player in player_zip:\n",
    "        name=player[0].string+' '+player[1].string;\n",
    "        jpg=player[-1]['src'];\n",
    "        player_list.append(Player(name=name, team=team, jpg=jpg))\n",
    "        \n",
    "    return player_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll collect photos from the 2000-2001 season to the 2018-2019 season using a list of rosters from every team in the NHL. Duplicates will be removed before images are collected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "seasonrange_floor=2000;\n",
    "seasonrange_ceiling=2020;\n",
    "all_players=[];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname=\"nhlroster_urls\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(fname) as f:\n",
    "    content = f.read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2004-2005 season unavailable.\n",
      "Team:  blackhawks , Season:  2001 added \n",
      "\n",
      "Team:  blackhawks , Season:  2002 added \n",
      "\n",
      "Team:  blackhawks , Season:  2003 added \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for page in content:\n",
    "    all_players=all_players+get_multiseasons(page, seasonrange_floor, seasonrange_ceiling);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see there have 7557 unique players in the NHL within the last 20 years. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_allplayers=list(dict.fromkeys(all_players))\n",
    "print(\"Unique players: \",len(reduced_allplayers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(reduced_allplayers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll store the images in our data directory, removing any images that have been removed from the site."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir=\"./project4_data/\"\n",
    "photos_unavailable=0;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(reduced_allplayers)):\n",
    "    try:\n",
    "        urllib.request.urlretrieve(reduced_allplayers[i].jpg, data_dir+reduced_allplayers[i].name+'.jpg')\n",
    "\n",
    "    except: \n",
    "        print(\"Player photgraph unavailable.\")\n",
    "        print(reduced_allplayers[i].jpg,i,reduced_allplayers[i].name)\n",
    "        photos_unavailable+=1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
